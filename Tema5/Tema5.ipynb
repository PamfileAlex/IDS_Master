{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 5 - Pamfile Alex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele de clasificare\n",
    "\n",
    "Folositi 5 seturi de date pentru probleme de clasificare, plecand de la repository-urile specificate in Cursul 6. Toate seturile de date trebuie sa aiba valori precizate (adica sa fie fara valori lipsa) si sa aiba macar o trasatura de intrare variabila categoriala nominala.\n",
    "\n",
    "1. Transformati trasaturile categoriale nominale folosind one hot encoding, https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html. \n",
    "1. (numar de modele * numar de seturi de date \\* 1 punct = 30 de puncte) Pentru fiecare set de date aplicati 6 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, precision, recall, scorul F1 - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics), [Precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall) - folosind 10 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor. \n",
    "3. (numar de modele * numar de seturi de date * 1 punct = 30 de puncte) Raportati performanta fiecarui model, folosind 10 fold cross validation. Pentru fiecare din cele 10 rulari, cautati hiperparametrii optimi folosind 4-fold cross validation. Performanta modelului va fi raportata ca medie a celor  10 rulari. \n",
    "    *Observatie:* la fiecare din cele 10 rulari, hiperparametrii optimi pot diferi, din cauza datelor utilizate pentru antrenare/validare. \n",
    "3. (numar modele * 4 puncte = 20 puncte) Documentati in jupyter notebook fiecare din modelele folosite, in limba romana. Daca acelasi algoritm e folosit pentru mai multe seturi de date, puteti face o sectiune separata cu documentarea algoritmilor + trimitere la algoritm. \n",
    "\n",
    "Se acorda 20 de puncte din oficiu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple de modele de clasificare:\n",
    "1. [Multi-layer Perceptron classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
    "1. [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "1. [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "1. [Gaussian processes](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html#sklearn.gaussian_process.GaussianProcessClassifier)\n",
    "1. [RBF](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html#sklearn.gaussian_process.kernels.RBF)\n",
    "1. [Decision tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "1. [Random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    "1. [Gaussian Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Predare:* \n",
    "1. Predarea se face cel tarziu in 25 noiembrie 2022 ora 23, in lucrarea de pe elearning (Tema 5). \n",
    "1. Obligatoriu: type annotations pentru variabile, parametri, tip de retur; docstrings. \n",
    "1. Fisierele de date folosite vor fi descarcate local de studenti si puse intr-un director \"data\". Se va realiza o arhiva zip care contine minim: fiserul/fisierele ipynb si direcotrul de date. Suplimentar, pot fi folosite imagini incluse in ipynb; acestea vor fi puse in directorul \"images\" ce se va include in arhiva zip predata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn version: 1.0.2\n",
      "Pandas version: 1.4.4\n",
      "Numpy version: 1.21.5\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Sklearn version:\", sklearn.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Numpy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Union\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "ModelClassifier = Union[KNeighborsClassifier, MultinomialNB, DecisionTreeClassifier, RandomForestClassifier, GradientBoostingClassifier]\n",
    "model_dict:Dict[str, ModelClassifier] = {\n",
    "        \"LinearSVC\" : LinearSVC(C=1.0),\n",
    "        \"KNeighborsClassifier\" : KNeighborsClassifier(n_neighbors=5, p=2),\n",
    "        \"MultinomialNB\" : MultinomialNB(alpha=1.0),\n",
    "        \"DecisionTreeClassifier\" : DecisionTreeClassifier(random_state=0, ccp_alpha=0.0),\n",
    "        \"RandomForestClassifier\" : RandomForestClassifier(random_state=0, n_estimators=100),\n",
    "        \"GradientBoostingClassifier\" : GradientBoostingClassifier(random_state=0, learning_rate=0.1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y:np.ndarray) -> pd.core.frame.DataFrame:\n",
    "    '''\n",
    "    Encodes using one hot method the classes vector using pandas.get_dummies method\n",
    "    :param y: numpy array, classes\n",
    "    :return: pandas DataFrame one hot encoded classes\n",
    "    '''\n",
    "    return pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def models_metrics(x:np.ndarray, y:np.ndarray, cv:int=10) -> None:\n",
    "    '''\n",
    "    Shows model metric for 6 different models\n",
    "    :param x: numpy array, atribute values\n",
    "    :param y: numpy array, classes\n",
    "    :param cv: int, number of folds\n",
    "    :return: None\n",
    "    '''\n",
    "    global model_dict\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1/3, shuffle=True)\n",
    "    print(\"#########################\")\n",
    "    print(f\"## Train distribution: {Counter(y_train)}\")\n",
    "    print(f\"## Test distribution: {Counter(y_test)}\")\n",
    "    print(\"#########################\\n\")\n",
    "    \n",
    "    for name, model in model_dict.items():\n",
    "        model.fit(x_train, y_train)\n",
    "        y_predicted:np.ndarray = model.predict(x_test)\n",
    "        print(name)\n",
    "        print(\"-----------------------\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_predicted))\n",
    "        print(\"Precision:\", precision_score(y_test, y_predicted, average='macro'))\n",
    "        print(\"Recall:\", recall_score(y_test, y_predicted, average='macro'))\n",
    "        print(\"F1 Score:\", f1_score(y_test, y_predicted, average='macro'))\n",
    "        \n",
    "        scores_train:np.ndarray = cross_val_score(model, x_train, y_train, cv=cv, scoring='accuracy')\n",
    "        scores_test:np.ndarray = cross_val_score(model, x_test, y_test, cv=cv, scoring='accuracy')\n",
    "        print(\"Trained fold mean:\", scores_train.mean())\n",
    "        print(\"Tested fold mean:\", scores_test.mean(), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_performances(x:np.ndarray, y:np.ndarray, cv:int=10) -> None:\n",
    "    '''\n",
    "    Shows performance for 6 different models\n",
    "    :param x: numpy array, atribute values\n",
    "    :param y: numpy array, classes\n",
    "    :param cv: int, number of folds\n",
    "    :return: None\n",
    "    '''\n",
    "    for name, model in model_dict.items():\n",
    "        print(name)\n",
    "        scores:np.ndarray = cross_val_score(model, x, y, cv=cv, scoring='accuracy')\n",
    "        print(\"Mean score:\", scores.mean(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameters(x:np.ndarray, y:np.ndarray, cv:int=4) -> None:\n",
    "    '''\n",
    "    Determines best hyperparameter for 6 different models\n",
    "    :param x: numpy array, atribute values\n",
    "    :param y: numpy array, classes\n",
    "    :param cv: int, number of folds\n",
    "    :return: None\n",
    "    '''\n",
    "    size:int = 10\n",
    "    print(\"LinearSVC\")\n",
    "    sample:np.ndarray = np.random.uniform(size=size)\n",
    "    scores_k:np.ndarray = np.array([cross_val_score(LinearSVC(C=k), x, y, cv=cv, scoring='accuracy').mean() for k in sample])\n",
    "    print('Optimal C parameter: {0}\\nMax score: {1}\\n'.format(sample[np.argmax(scores_k)], np.max(scores_k)))\n",
    "    \n",
    "    print(\"KNeighborsClassifier\")\n",
    "    scores_k:np.ndarray = np.array([cross_val_score(KNeighborsClassifier(n_neighbors=k), x, y, cv=cv, scoring='accuracy').mean() for k in range(1, size)])\n",
    "    print('Optimal n_neighbors parameter: {0}\\nMax score: {1}\\n'.format(1+np.argmax(scores_k), np.max(scores_k)))\n",
    "    \n",
    "    print(\"MultinomialNB\")\n",
    "    sample:np.ndarray = np.random.uniform(size=size)\n",
    "    scores_k:np.ndarray = np.array([cross_val_score( MultinomialNB(alpha=k), x, y, cv=cv, scoring='accuracy').mean() for k in sample])\n",
    "    print('Optimal alpha parameter: {0}\\nMax score: {1}\\n'.format(sample[np.argmax(scores_k)], np.max(scores_k)))\n",
    "    \n",
    "    print(\"DecisionTreeClassifier\")\n",
    "    sample:np.ndarray = np.random.uniform(size=size)\n",
    "    scores_k:np.ndarray = np.array([cross_val_score(DecisionTreeClassifier(random_state=0, ccp_alpha=k), x, y, cv=cv, scoring='accuracy').mean() for k in sample])\n",
    "    print('Optimal ccp_alpha parameter: {0}\\nMax score: {1}\\n'.format(sample[np.argmax(scores_k)], np.max(scores_k)))\n",
    "    \n",
    "    print(\"RandomForestClassifier\")\n",
    "    sample:np.ndarray = np.random.randint(low=10, high=100, size=size)\n",
    "    scores_k:np.ndarray = np.array([cross_val_score(RandomForestClassifier(random_state=0, n_estimators=k), x, y, cv=cv, scoring='accuracy').mean() for k in sample])\n",
    "    print('Optimal n_estimators parameter: {0}\\nMax score: {1}\\n'.format(sample[np.argmax(scores_k)], np.max(scores_k)))\n",
    "    \n",
    "    print(\"GradientBoostingClassifier\")\n",
    "    sample:np.ndarray = np.random.uniform(size=size, high=0.3)\n",
    "    scores_k:np.ndarray = np.array([cross_val_score(GradientBoostingClassifier(random_state=0, learning_rate=k), x, y, cv=cv, scoring='accuracy').mean() for k in sample])\n",
    "    print('Optimal learning_rate parameter: {0}\\nMax score: {1}\\n'.format(sample[np.argmax(scores_k)], np.max(scores_k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Dataset\n",
    "http://archive.ics.uci.edu/ml/datasets/Iris \\\n",
    "Missing Values: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (150, 5)\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "iris_data:pd.core.frame.DataFrame = pd.read_csv(\"./data/iris.data\", header=None)\n",
    "iris_values:np.ndarray = iris_data.values\n",
    "print(f\"Shape: {iris_values.shape}\")\n",
    "print(f\"Missing values: {pd.isnull(iris_values).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_x:np.ndarray = iris_values[:,:-1]\n",
    "iris_y:np.ndarray = iris_values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "0              1                0               0\n",
       "1              1                0               0\n",
       "2              1                0               0\n",
       "3              1                0               0\n",
       "4              1                0               0\n",
       "..           ...              ...             ...\n",
       "145            0                0               1\n",
       "146            0                0               1\n",
       "147            0                0               1\n",
       "148            0                0               1\n",
       "149            0                0               1\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(iris_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "## Train distribution: Counter({'Iris-setosa': 34, 'Iris-virginica': 33, 'Iris-versicolor': 33})\n",
      "## Test distribution: Counter({'Iris-versicolor': 17, 'Iris-virginica': 17, 'Iris-setosa': 16})\n",
      "#########################\n",
      "\n",
      "LinearSVC\n",
      "-----------------------\n",
      "Accuracy: 0.96\n",
      "Precision: 0.9649122807017544\n",
      "Recall: 0.9607843137254902\n",
      "F1 Score: 0.9606481481481483\n",
      "Trained fold mean: 0.96\n",
      "Tested fold mean: 0.9800000000000001\n",
      "\n",
      "KNeighborsClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.96\n",
      "Precision: 0.9649122807017544\n",
      "Recall: 0.9607843137254902\n",
      "F1 Score: 0.9606481481481483\n",
      "Trained fold mean: 0.9700000000000001\n",
      "Tested fold mean: 0.96\n",
      "\n",
      "MultinomialNB\n",
      "-----------------------\n",
      "Accuracy: 0.94\n",
      "Precision: 0.9421296296296297\n",
      "Recall: 0.9411764705882352\n",
      "F1 Score: 0.9411255411255411\n",
      "Trained fold mean: 0.95\n",
      "Tested fold mean: 0.9199999999999999\n",
      "\n",
      "DecisionTreeClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.96\n",
      "Precision: 0.9649122807017544\n",
      "Recall: 0.9607843137254902\n",
      "F1 Score: 0.9606481481481483\n",
      "Trained fold mean: 0.9700000000000001\n",
      "Tested fold mean: 0.96\n",
      "\n",
      "RandomForestClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.96\n",
      "Precision: 0.9649122807017544\n",
      "Recall: 0.9607843137254902\n",
      "F1 Score: 0.9606481481481483\n",
      "Trained fold mean: 0.9700000000000001\n",
      "Tested fold mean: 0.96\n",
      "\n",
      "GradientBoostingClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.96\n",
      "Precision: 0.9649122807017544\n",
      "Recall: 0.9607843137254902\n",
      "F1 Score: 0.9606481481481483\n",
      "Trained fold mean: 0.9700000000000001\n",
      "Tested fold mean: 0.9199999999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_metrics(iris_x, iris_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Mean score: 0.9666666666666668 \n",
      "\n",
      "KNeighborsClassifier\n",
      "Mean score: 0.9666666666666668 \n",
      "\n",
      "MultinomialNB\n",
      "Mean score: 0.9533333333333334 \n",
      "\n",
      "DecisionTreeClassifier\n",
      "Mean score: 0.96 \n",
      "\n",
      "RandomForestClassifier\n",
      "Mean score: 0.96 \n",
      "\n",
      "GradientBoostingClassifier\n",
      "Mean score: 0.96 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_performances(iris_x, iris_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Optimal C parameter: 0.4199344473847224\n",
      "Max score: 0.9598150782361308\n",
      "\n",
      "KNeighborsClassifier\n",
      "Optimal n_neighbors parameter: 5\n",
      "Max score: 0.9667496443812233\n",
      "\n",
      "MultinomialNB\n",
      "Optimal alpha parameter: 0.2788862401512243\n",
      "Max score: 0.9731507823613087\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Optimal ccp_alpha parameter: 0.11254199966588962\n",
      "Max score: 0.9466571834992887\n",
      "\n",
      "RandomForestClassifier\n",
      "Optimal n_estimators parameter: 21\n",
      "Max score: 0.9599928876244666\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Optimal learning_rate parameter: 0.18854089032848845\n",
      "Max score: 0.9667496443812233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyperparameters(iris_x, iris_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Dataset\n",
    "http://archive.ics.uci.edu/ml/datasets/Wine \\\n",
    "Missing Values: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (178, 14)\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "wine_data:pd.core.frame.DataFrame = pd.read_csv(\"./data/wine.data\", header=None)\n",
    "wine_values:np.ndarray = wine_data.values\n",
    "print(f\"Shape: {wine_values.shape}\")\n",
    "print(f\"Missing values: {pd.isnull(wine_values).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_x:np.ndarray = wine_values[:,1:]\n",
    "wine_y:np.ndarray = wine_values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1.0  2.0  3.0\n",
       "0      1    0    0\n",
       "1      1    0    0\n",
       "2      1    0    0\n",
       "3      1    0    0\n",
       "4      1    0    0\n",
       "..   ...  ...  ...\n",
       "173    0    0    1\n",
       "174    0    0    1\n",
       "175    0    0    1\n",
       "176    0    0    1\n",
       "177    0    0    1\n",
       "\n",
       "[178 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(wine_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "## Train distribution: Counter({2.0: 50, 1.0: 39, 3.0: 29})\n",
      "## Test distribution: Counter({2.0: 21, 1.0: 20, 3.0: 19})\n",
      "#########################\n",
      "\n",
      "LinearSVC\n",
      "-----------------------\n",
      "Accuracy: 0.8\n",
      "Precision: 0.8366666666666666\n",
      "Recall: 0.7953634085213032\n",
      "F1 Score: 0.7925925925925926\n",
      "Trained fold mean: 0.8287878787878787\n",
      "Tested fold mean: 0.65\n",
      "\n",
      "KNeighborsClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.7\n",
      "Precision: 0.7028265851795265\n",
      "Recall: 0.7010025062656643\n",
      "F1 Score: 0.6983311938382543\n",
      "Trained fold mean: 0.7007575757575758\n",
      "Tested fold mean: 0.6499999999999999\n",
      "\n",
      "MultinomialNB\n",
      "-----------------------\n",
      "Accuracy: 0.8833333333333333\n",
      "Precision: 0.8962962962962964\n",
      "Recall: 0.8814954051796157\n",
      "F1 Score: 0.8844496670583627\n",
      "Trained fold mean: 0.8363636363636363\n",
      "Tested fold mean: 0.8833333333333332\n",
      "\n",
      "DecisionTreeClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.939855072463768\n",
      "Recall: 0.934126984126984\n",
      "F1 Score: 0.934122934122934\n",
      "Trained fold mean: 0.9409090909090908\n",
      "Tested fold mean: 0.8833333333333332\n",
      "\n",
      "RandomForestClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.9833333333333333\n",
      "Precision: 0.9848484848484849\n",
      "Recall: 0.9833333333333334\n",
      "F1 Score: 0.9837010534684953\n",
      "Trained fold mean: 0.975\n",
      "Tested fold mean: 0.95\n",
      "\n",
      "GradientBoostingClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.9349206349206348\n",
      "Recall: 0.9340434419381788\n",
      "F1 Score: 0.934065934065934\n",
      "Trained fold mean: 0.9227272727272726\n",
      "Tested fold mean: 0.85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_metrics(wine_x, wine_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Mean score: 0.8833333333333332 \n",
      "\n",
      "KNeighborsClassifier\n",
      "Mean score: 0.6754901960784313 \n",
      "\n",
      "MultinomialNB\n",
      "Mean score: 0.8496732026143791 \n",
      "\n",
      "DecisionTreeClassifier\n",
      "Mean score: 0.8705882352941178 \n",
      "\n",
      "RandomForestClassifier\n",
      "Mean score: 0.9833333333333332 \n",
      "\n",
      "GradientBoostingClassifier\n",
      "Mean score: 0.9160130718954248 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_performances(wine_x, wine_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Optimal C parameter: 0.021467787639915525\n",
      "Max score: 0.9108585858585858\n",
      "\n",
      "KNeighborsClassifier\n",
      "Optimal n_neighbors parameter: 1\n",
      "Max score: 0.7193181818181817\n",
      "\n",
      "MultinomialNB\n",
      "Optimal alpha parameter: 0.9609296649121679\n",
      "Max score: 0.8327020202020202\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Optimal ccp_alpha parameter: 0.12319987583789394\n",
      "Max score: 0.8319444444444444\n",
      "\n",
      "RandomForestClassifier\n",
      "Optimal n_estimators parameter: 82\n",
      "Max score: 0.9609848484848484\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Optimal learning_rate parameter: 0.2141054561039081\n",
      "Max score: 0.9386363636363637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyperparameters(wine_x, wine_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haberman's Survival Dataset\n",
    "http://archive.ics.uci.edu/ml/datasets/Haberman%27s+Survival \\\n",
    "Missing Values: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (306, 4)\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "haberman_data:pd.core.frame.DataFrame = pd.read_csv(\"./data/haberman.data\", header=None)\n",
    "haberman_values:np.ndarray = haberman_data.values.astype(np.float64)\n",
    "print(f\"Shape: {haberman_values.shape}\")\n",
    "print(f\"Missing values: {pd.isnull(haberman_values).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "haberman_x:np.ndarray = haberman_values[:,:-1]\n",
    "haberman_y:np.ndarray = haberman_values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1.0  2.0\n",
       "0      1    0\n",
       "1      1    0\n",
       "2      1    0\n",
       "3      1    0\n",
       "4      1    0\n",
       "..   ...  ...\n",
       "301    1    0\n",
       "302    1    0\n",
       "303    1    0\n",
       "304    0    1\n",
       "305    0    1\n",
       "\n",
       "[306 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(haberman_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "## Train distribution: Counter({1.0: 146, 2.0: 58})\n",
      "## Test distribution: Counter({1.0: 79, 2.0: 23})\n",
      "#########################\n",
      "\n",
      "LinearSVC\n",
      "-----------------------\n",
      "Accuracy: 0.7647058823529411\n",
      "Precision: 0.6200716845878136\n",
      "Recall: 0.5553109521188773\n",
      "F1 Score: 0.5552325581395349\n",
      "Trained fold mean: 0.6071428571428571\n",
      "Tested fold mean: 0.7300000000000001\n",
      "\n",
      "KNeighborsClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.6862745098039216\n",
      "Precision: 0.5509080902586682\n",
      "Recall: 0.5509080902586682\n",
      "F1 Score: 0.5509080902586682\n",
      "Trained fold mean: 0.7445238095238096\n",
      "Tested fold mean: 0.7063636363636363\n",
      "\n",
      "MultinomialNB\n",
      "-----------------------\n",
      "Accuracy: 0.7156862745098039\n",
      "Precision: 0.6153474903474904\n",
      "Recall: 0.631535498073748\n",
      "F1 Score: 0.6209150326797386\n",
      "Trained fold mean: 0.74\n",
      "Tested fold mean: 0.7354545454545455\n",
      "\n",
      "DecisionTreeClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.6764705882352942\n",
      "Precision: 0.5861607142857144\n",
      "Recall: 0.6062190423775454\n",
      "F1 Score: 0.589261744966443\n",
      "Trained fold mean: 0.6661904761904763\n",
      "Tested fold mean: 0.6363636363636364\n",
      "\n",
      "RandomForestClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.6666666666666666\n",
      "Precision: 0.5361038961038962\n",
      "Recall: 0.5382498624105669\n",
      "F1 Score: 0.5368589743589745\n",
      "Trained fold mean: 0.7295238095238095\n",
      "Tested fold mean: 0.6963636363636364\n",
      "\n",
      "GradientBoostingClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.6862745098039216\n",
      "Precision: 0.5509080902586682\n",
      "Recall: 0.5509080902586682\n",
      "F1 Score: 0.5509080902586682\n",
      "Trained fold mean: 0.6900000000000001\n",
      "Tested fold mean: 0.6872727272727273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_metrics(haberman_x, haberman_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Mean score: 0.6320430107526882 \n",
      "\n",
      "KNeighborsClassifier\n",
      "Mean score: 0.7027956989247313 \n",
      "\n",
      "MultinomialNB\n",
      "Mean score: 0.7388172043010753 \n",
      "\n",
      "DecisionTreeClassifier\n",
      "Mean score: 0.6021505376344086 \n",
      "\n",
      "RandomForestClassifier\n",
      "Mean score: 0.6931182795698925 \n",
      "\n",
      "GradientBoostingClassifier\n",
      "Mean score: 0.6189247311827957 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_performances(haberman_x, haberman_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Optimal C parameter: 0.044740092614624194\n",
      "Max score: 0.7450444292549556\n",
      "\n",
      "KNeighborsClassifier\n",
      "Optimal n_neighbors parameter: 8\n",
      "Max score: 0.7485047846889952\n",
      "\n",
      "MultinomialNB\n",
      "Optimal alpha parameter: 0.2941847130437514\n",
      "Max score: 0.7387218045112782\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Optimal ccp_alpha parameter: 0.05935464490240505\n",
      "Max score: 0.7353041695146959\n",
      "\n",
      "RandomForestClassifier\n",
      "Optimal n_estimators parameter: 46\n",
      "Max score: 0.669771018455229\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Optimal learning_rate parameter: 0.015274518058623442\n",
      "Max score: 0.669471975393028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyperparameters(haberman_x, haberman_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yeast Dataset\n",
    "https://archive.ics.uci.edu/ml/datasets/Yeast \\\n",
    "Missing Values: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1484, 10)\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "yeast_data:pd.core.frame.DataFrame = pd.read_csv(\"./data/yeast.data\", header=None)\n",
    "yeast_values:np.ndarray = yeast_data.values\n",
    "print(f\"Shape: {yeast_values.shape}\")\n",
    "print(f\"Missing values: {pd.isnull(yeast_values).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeast_x:np.ndarray = yeast_values[:,1:-1]\n",
    "yeast_y:np.ndarray = yeast_values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CYT</th>\n",
       "      <th>ERL</th>\n",
       "      <th>EXC</th>\n",
       "      <th>ME1</th>\n",
       "      <th>ME2</th>\n",
       "      <th>ME3</th>\n",
       "      <th>MIT</th>\n",
       "      <th>NUC</th>\n",
       "      <th>POX</th>\n",
       "      <th>VAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1484 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CYT  ERL  EXC  ME1  ME2  ME3  MIT  NUC  POX  VAC\n",
       "0       0    0    0    0    0    0    1    0    0    0\n",
       "1       0    0    0    0    0    0    1    0    0    0\n",
       "2       0    0    0    0    0    0    1    0    0    0\n",
       "3       0    0    0    0    0    0    0    1    0    0\n",
       "4       0    0    0    0    0    0    1    0    0    0\n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "1479    0    0    0    0    1    0    0    0    0    0\n",
       "1480    0    0    0    0    0    0    0    1    0    0\n",
       "1481    0    0    0    0    1    0    0    0    0    0\n",
       "1482    0    0    0    0    0    0    0    1    0    0\n",
       "1483    1    0    0    0    0    0    0    0    0    0\n",
       "\n",
       "[1484 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(yeast_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "## Train distribution: Counter({'CYT': 308, 'NUC': 291, 'MIT': 158, 'ME3': 111, 'ME1': 33, 'ME2': 28, 'EXC': 23, 'VAC': 21, 'POX': 12, 'ERL': 4})\n",
      "## Test distribution: Counter({'CYT': 155, 'NUC': 138, 'MIT': 86, 'ME3': 52, 'ME2': 23, 'EXC': 12, 'ME1': 11, 'VAC': 9, 'POX': 8, 'ERL': 1})\n",
      "#########################\n",
      "\n",
      "LinearSVC\n",
      "-----------------------\n",
      "Accuracy: 0.5777777777777777\n",
      "Precision: 0.48098352032314295\n",
      "Recall: 0.4004740456169074\n",
      "F1 Score: 0.389021948204878\n",
      "Trained fold mean: 0.5894248608534323\n",
      "Tested fold mean: 0.5657551020408162\n",
      "\n",
      "KNeighborsClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.5313131313131313\n",
      "Precision: 0.5527953325356328\n",
      "Recall: 0.5312645776980882\n",
      "F1 Score: 0.5230662333775176\n",
      "Trained fold mean: 0.5631313131313131\n",
      "Tested fold mean: 0.545469387755102\n",
      "\n",
      "MultinomialNB\n",
      "-----------------------\n",
      "Accuracy: 0.33131313131313134\n",
      "Precision: 0.09713407542781193\n",
      "Recall: 0.1071575502571295\n",
      "F1 Score: 0.06830452285105375\n",
      "Trained fold mean: 0.3437950937950938\n",
      "Tested fold mean: 0.3112244897959183\n",
      "\n",
      "DecisionTreeClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.503030303030303\n",
      "Precision: 0.4068588992974239\n",
      "Recall: 0.40092167861819517\n",
      "F1 Score: 0.40098389822766684\n",
      "Trained fold mean: 0.5075860647289219\n",
      "Tested fold mean: 0.4766122448979592\n",
      "\n",
      "RandomForestClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.6242424242424243\n",
      "Precision: 0.6336330302307128\n",
      "Recall: 0.604853237480851\n",
      "F1 Score: 0.6042836579855619\n",
      "Trained fold mean: 0.6278602350030922\n",
      "Tested fold mean: 0.5777551020408163\n",
      "\n",
      "GradientBoostingClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.591919191919192\n",
      "Precision: 0.5853916321821917\n",
      "Recall: 0.5480728843658162\n",
      "F1 Score: 0.5162833288891377\n",
      "Trained fold mean: 0.5924448567305709\n",
      "Tested fold mean: 0.5373877551020408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_metrics(yeast_x, yeast_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Mean score: 0.5754670778160711 \n",
      "\n",
      "KNeighborsClassifier\n",
      "Mean score: 0.5437828768365681 \n",
      "\n",
      "MultinomialNB\n",
      "Mean score: 0.32750317431525483 \n",
      "\n",
      "DecisionTreeClassifier\n",
      "Mean score: 0.465608561581716 \n",
      "\n",
      "RandomForestClassifier\n",
      "Mean score: 0.6037456920007255 \n",
      "\n",
      "GradientBoostingClassifier\n",
      "Mean score: 0.5794395066207148 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_performances(yeast_x, yeast_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Optimal C parameter: 0.9875029514458578\n",
      "Max score: 0.5747978436657681\n",
      "\n",
      "KNeighborsClassifier\n",
      "Optimal n_neighbors parameter: 9\n",
      "Max score: 0.570754716981132\n",
      "\n",
      "MultinomialNB\n",
      "Optimal alpha parameter: 0.01627461166974853\n",
      "Max score: 0.33423180592991913\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Optimal ccp_alpha parameter: 0.6455065007215198\n",
      "Max score: 0.3119946091644205\n",
      "\n",
      "RandomForestClassifier\n",
      "Optimal n_estimators parameter: 95\n",
      "Max score: 0.5862533692722371\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Optimal learning_rate parameter: 0.04355796934040276\n",
      "Max score: 0.5700808625336927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyperparameters(yeast_x, yeast_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Scale Dataset\n",
    "https://archive.ics.uci.edu/ml/datasets/Balance+Scale \\\n",
    "Missing Values: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (625, 5)\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "balance_scales_data:pd.core.frame.DataFrame = pd.read_csv(\"./data/balance_scale.data\", header=None)\n",
    "balance_scales_values:np.ndarray = balance_scales_data.values\n",
    "print(f\"Shape: {balance_scales_values.shape}\")\n",
    "print(f\"Missing values: {pd.isnull(balance_scales_values).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_scales_x:np.ndarray = balance_scales_values[:,1:]\n",
    "balance_scales_y:np.ndarray = balance_scales_values[:,0].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>L</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     B  L  R\n",
       "0    1  0  0\n",
       "1    0  0  1\n",
       "2    0  0  1\n",
       "3    0  0  1\n",
       "4    0  0  1\n",
       "..  .. .. ..\n",
       "620  0  1  0\n",
       "621  0  1  0\n",
       "622  0  1  0\n",
       "623  0  1  0\n",
       "624  1  0  0\n",
       "\n",
       "[625 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(balance_scales_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "## Train distribution: Counter({'R': 197, 'L': 193, 'B': 26})\n",
      "## Test distribution: Counter({'L': 95, 'R': 91, 'B': 23})\n",
      "#########################\n",
      "\n",
      "LinearSVC\n",
      "-----------------------\n",
      "Accuracy: 0.8373205741626795\n",
      "Precision: 0.5588379204892967\n",
      "Recall: 0.627299016772701\n",
      "F1 Score: 0.5910241932724224\n",
      "Trained fold mean: 0.8775261324041812\n",
      "Tested fold mean: 0.8323809523809524\n",
      "\n",
      "KNeighborsClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.8277511961722488\n",
      "Precision: 0.5691906855560983\n",
      "Recall: 0.6193560825139772\n",
      "F1 Score: 0.5915343915343915\n",
      "Trained fold mean: 0.8653310104529618\n",
      "Tested fold mean: 0.78\n",
      "\n",
      "MultinomialNB\n",
      "-----------------------\n",
      "Accuracy: 0.8564593301435407\n",
      "Precision: 0.5713455657492355\n",
      "Recall: 0.6414883362251783\n",
      "F1 Score: 0.6043185162372104\n",
      "Trained fold mean: 0.8872241579558653\n",
      "Tested fold mean: 0.8276190476190475\n",
      "\n",
      "DecisionTreeClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.7894736842105263\n",
      "Precision: 0.5858560090702948\n",
      "Recall: 0.6025783522351028\n",
      "F1 Score: 0.5929983967092446\n",
      "Trained fold mean: 0.8054006968641115\n",
      "Tested fold mean: 0.718095238095238\n",
      "\n",
      "RandomForestClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.8181818181818182\n",
      "Precision: 0.5643564356435643\n",
      "Recall: 0.6131096973202236\n",
      "F1 Score: 0.5876558956916099\n",
      "Trained fold mean: 0.872822299651568\n",
      "Tested fold mean: 0.7461904761904762\n",
      "\n",
      "GradientBoostingClassifier\n",
      "-----------------------\n",
      "Accuracy: 0.84688995215311\n",
      "Precision: 0.6254458093917178\n",
      "Recall: 0.6453005423257139\n",
      "F1 Score: 0.6278866493920257\n",
      "Trained fold mean: 0.8702090592334495\n",
      "Tested fold mean: 0.7416666666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_metrics(balance_scales_x, balance_scales_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Mean score: 0.8480798771121352 \n",
      "\n",
      "KNeighborsClassifier\n",
      "Mean score: 0.7472606246799794 \n",
      "\n",
      "MultinomialNB\n",
      "Mean score: 0.8592933947772657 \n",
      "\n",
      "DecisionTreeClassifier\n",
      "Mean score: 0.6704301075268816 \n",
      "\n",
      "RandomForestClassifier\n",
      "Mean score: 0.6815924219150026 \n",
      "\n",
      "GradientBoostingClassifier\n",
      "Mean score: 0.7119559651817715 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_performances(balance_scales_x, balance_scales_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Optimal C parameter: 0.33138494239049765\n",
      "Max score: 0.8480013882083945\n",
      "\n",
      "KNeighborsClassifier\n",
      "Optimal n_neighbors parameter: 8\n",
      "Max score: 0.8032622897272579\n",
      "\n",
      "MultinomialNB\n",
      "Optimal alpha parameter: 0.26032780229273345\n",
      "Max score: 0.8287706189776254\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Optimal ccp_alpha parameter: 0.06166726488492469\n",
      "Max score: 0.513688143067124\n",
      "\n",
      "RandomForestClassifier\n",
      "Optimal n_estimators parameter: 55\n",
      "Max score: 0.6450269475747183\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Optimal learning_rate parameter: 0.2537635611540968\n",
      "Max score: 0.686693614241385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyperparameters(balance_scales_x, balance_scales_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LinearSVC\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
    "\n",
    "Linear Support Vector Machine (Linear SVC) este un algoritm care încearcă să găsească un hiperplan pentru a maximiza distanța dintre mostrele clasificate. Metoda SVC aplică o funcție de kernel liniară pentru a realiza clasificarea și se comportă bine cu un număr mare de mostre. Dacă îl comparăm cu modelul SVC, SVC-ul liniar are parametri suplimentari, cum ar fi normalizarea penalizării care aplică \"L1\" sau \"L2\" și funcția de pierdere (loss function). Metoda kernelului nu poate fi schimbată în SVC liniar, deoarece se bazează pe metoda liniară kernel. \n",
    "\n",
    "În cazul în care datele de instruire sunt separabile liniar, putem selecta două hiperplane paralele care separă cele două clase de date, astfel încât distanța dintre ele să fie cât mai mare posibil. Regiunea delimitată de aceste două hiperplane se numește \"marjă\", iar hiperplanul cu marjă maximă este hiperplanul care se află la jumătatea distanței dintre ele.\n",
    "\n",
    "Implementarea C subiacentă utilizează un generator de numere aleatoare pentru a selecta caracteristicile atunci când se ajustează modelul. Prin urmare, nu este neobișnuit să se obțină rezultate ușor diferite pentru aceleași date de intrare. Dacă se întâmplă acest lucru, se recomanda incercarea cu un parametru tol mai mic. Implementarea de bază, liblinear, utilizează o reprezentare internă dispersată pentru date, ceea ce implică o copie în memorie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. KNeighborsClassifier\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "K Nearerst Neighbors (kNN, k-NN) este un model de clasificare si regresie din categoria Case Based Reasoning, un stil de lucru in care deciziile se iau pe baza cautarii intr-o baza de experiente anterioare inregistrate. Este suficient de simplu pentru a putea fi implementat in mai putin de 20 de minute. Poate fi extins pentru regresie. In ciuda simplitatii, este considerat robust si util pentru multe probleme si a fost inclus in [Top 10 data mining algorithms](https://www.kdnuggets.com/2015/05/top-10-data-mining-algorithms-explained.html)\n",
    "\n",
    "El memoreaza cazurile cunoscute, iar pentru o situatie la care se cere raspuns (clasificare sau regresie) gaseste cele mai apropiate  𝑘  cazuri si formuleaza raspunsul prin combinarea raspunsurilor de la acestea. Modelul este neparametric: raspunsul nu depinde de vreo presupunere apriorica asupra modului in care raspunsul este format, ci este dat de continutul bazei de cunostinte, si desigur influentat de numarul de vecini considerati ( 𝑘 ) si de modul de calcul al distantei.\n",
    "\n",
    "Pentru clasificare, principiul de lucru este simplu:\n",
    "- se gasesc cei mai apropiati  𝑘  vecini fata de cazul pentru care se solicita clasificarea\n",
    "- se gaseste clasa majoritara si se considera ca elementul nou face parte din aceasta clasa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MultinomialNB\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "\n",
    "Metodele Naive Bayes sunt un set de algoritmi de invatare supravegheati pe baza aplicarii teoremei lui Bayes cu presupunerea \"naiva\" a independentei conditionate intre fiecare pereche de atribute, data fiind valoarea variabilei de clasa.\n",
    "\n",
    "Multinomial Naive Bayes presupune a avea un vector de caracteristici unde fiecare element reprezinta de cate ori apare (sau, foarte des, frecventa sa). Aceasta tehnica este foarte eficienta in procesarea limbii natale sau sau ori de cate ori mostrele sunt compuse pornind de la un dictionar comun.\n",
    "\n",
    "O distributie multinomiala este utila pentru modelarea vectorilor de caracteristici in care fiecare valoare reprezinta, de exemplu, numarul de aparitii ale unui termen sau frecventa sa relativa.\n",
    "\n",
    "MultinomialNB presupune ca, caracteristicile au distributie multinomiala, care este o generalizare a distributiei binomiale.\n",
    "\n",
    "Clasificatorul multinomial Naive Bayes este potrivit pentru clasificarea cu atribute discrete (de exemplu, numarul de cuvinte pentru clasificarea textului)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. DecisionTreeClassifier\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "Un arbore de decizie este o structura de arbore asemanatoare unei diagrame in care un nod intern reprezinta caracteristica (sau atribut), ramura reprezinta o regula de decizie si fiecare nod frunza reprezinta rezultatul. Cel mai de sus nod dintr-un arbore de decizie este cunoscut sub numele de nod radacina. Invata sa partitioneze pe baza valorii atributului. Arborele se partitioneaza in mod recursiv, numita partitionare recursiva.\n",
    "\n",
    "Arborele de decizie este un algoritm de Machine Learning de tip \"white box\". Impartaseste logica interna de luare a deciziilor, care nu este disponibila in tipul \"black box\" de algoritmi, cum ar fi Reteaua neuronala. Timpul sau de antrenare este mai rapid in comparatie cu algoritmul retelei neuronale. Complexitatea in timp a arborilor de decizie se bazeaza pe numarului de inregistrari cat si pe numarului de atribute din datele primite. Arborii de decizie pot gestiona datele cu dimensiuni foarte mari cu o precizie buna.\n",
    "\n",
    "Ideea de baza din spatele oricarui algoritm al arborelui decizional este urmatoarea:\n",
    "\n",
    "- Selectarea celui mai bun atribut folosind masuri de selectie a atributelor (Attribute Selection Measures sau ASM) pentru a imparti inregistrarile\n",
    "- Transformarea atributului intr-un nod de decizie si ruperea setului de date in subseturi mai mici.\n",
    "- Construirea arborelui prin repetarea acestui proces recursiv pentru fiecare nod copil pana cand una dintre conditii se va potrivi:\n",
    "  - Toate tuplurile apartin aceleiasi valori de atribut.\n",
    "  - There are no more remaining attributes.\n",
    "  - Nu mai exista atribute ramase.\n",
    "  - Nu mai exista instante.\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. RandomForestClassifier\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "Un Random Forest este un estimator care se potriveste cu un numar de clasificatori de tip arbori de decizie pe diferite sample-uri ale setului de date si care utilizeaza media pentru a imbunatati precizia si a controla over-fitting-ul.\n",
    "\n",
    "Random Forest este un algoritm de invatare supervizat. \"Padurea\" construita este un ansamblu de arbori de decizie, de obicei instruiti prin metoda \"bagging\" sau a \"impachetarii\".\n",
    "\n",
    "Ideea generala a acestei metode este ca o combinatie de modele de invatare mareste rezultatul general. Astfel, in loc sa caute cea mai importanta caracteristica sau cel mai important atribut in timp ce imparte un nod, cauta cel mai bun atribut dintr-un subset de atribute aleatorii. Acest lucru are ca rezultat o mare diversitate care, in general, duce la un model mai bun si care previne over-fitting-ul.\n",
    "\n",
    "Asadar, in Random Forest, doar un subset aleatoriu de caracteristici este luat in considerare de algoritmul pentru divizarea unui nod. De asemenea, modelul este eficient si pentru ca hiperparametrii impliciti produc adesea un rezultat bun de predictie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. GradientBoostingClassifier\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "\n",
    "Gradient boosting este un algoritm de tip Greedy care poate produce over-fitting pe un set de date.\n",
    "\n",
    "Acest model poate beneficia de metode de regularizare pe diferite parti ale algoritmului care imbunatatesc performanta si reduc over fitting-ul.\n",
    "La baza Gradient Boosting-ului se afla ideea de a lua un algoritm relativ slab de invatare si de a face o serie de modificari care sa imbunatateasca puterea acestuia de procesare sau \"learner-ii\"\n",
    "\n",
    "Ideea aceasta a fost realizata initial in algoritmul Adaptive Boosting (AdaBoost). Pentru AdaBoost, multi \"learneri\" slabi sunt creati prin initializarea multor algoritmi de decizie care au doar o singura impartire. In AdaBoost, predictiile se fac printr-o metoda numita majority vote sau vot majoritar, in care instantele sunt clasificate in functie de clasa care primeste cele mai multe voturi de la acesti \"learneri\" slabi.\n",
    "\n",
    "Modelul Gradient Boosting foloseste algoritmul AdaBoost combinat cu metoda minimizarii ponderate, unde clasificatorii si input-urile ponderate sunt recalculate. Obiectivul modelului Gradient Boosting este acela de a minimiza costul sau diferenta dintre valorile prezise si valorile actuale pe setul de antrenare.\n",
    "\n",
    "De asemenea, modelul Gradient Boosting foloseste arbori de decizie pe post de \"learneri\" slabi.\n",
    "\n",
    "Deoarece modelul Gradient Boosting poate produce over-fitting, se utilizeaza diferite constrangeri sau metode de regularizare pentru a spori performanta algoritmului. Astfel, invatarea penalizata folosing regularizarile L1 sau L2 sau tree constraints sunt solutii posibile pentru a combate over-fitting-ul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
